{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# MIA attacks on Length-of-Stay predictor, Logistic Regression\n",
            "## Installation of Packages in Conda\n",
            "\n",
            "To install the required packages in your conda environment, you can use the following commands:\n",
            "\n",
            "```bash\n",
            "conda install h5py\n",
            "conda install pytables\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import sys\n",
            "\n",
            "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../../\"))  # adjust as needed\n",
            "if project_root not in sys.path:\n",
            "    sys.path.insert(0, project_root)  # insert at the front to prioritize it\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Train the classifier\n",
            "### Load the dataset\n",
            "The dataset is generated by the notebook file `mimic_dataset_prep.ipynb`."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import yaml\n",
            "import pickle\n",
            "\n",
            "# Load the config.yaml file\n",
            "with open(\"train_config.yaml\", \"r\") as file:\n",
            "    train_config = yaml.safe_load(file)\n",
            "\n",
            "# Determine training method and paths\n",
            "assert train_config['train']['training_method'] == 'LR', \"The training config is not set to use LR\"\n",
            "use_LR = train_config['train']['training_method'] == 'LR'\n",
            "data_path = train_config['data']['data_dir']\n",
            "path = os.path.join(data_path, \"LR_data\" if use_LR else \"GRUD_data\")\n",
            "\n",
            "# File paths\n",
            "dataset_path = os.path.join(path, \"dataset.pkl\")\n",
            "indices_path = os.path.join(path, \"indices.pkl\")\n",
            "\n",
            "# Load dataset and indices\n",
            "if os.path.exists(dataset_path) and os.path.exists(indices_path):\n",
            "    print(\"Loading dataset...\")\n",
            "    \n",
            "    with open(dataset_path, \"rb\") as f:\n",
            "        dataset = pickle.load(f)\n",
            "\n",
            "    with open(indices_path, \"rb\") as f:\n",
            "        indices_dict = pickle.load(f)\n",
            "        train_indices = indices_dict[\"train_indices\"]\n",
            "        test_indices = indices_dict[\"test_indices\"]\n",
            "        early_stop_indices = indices_dict[\"early_stop_indices\"]\n",
            "        #TODO: fix this\n",
            "        data_indices = train_indices + test_indices + early_stop_indices\n",
            "\n",
            "    print(f\"Loaded dataset and indices from {path}\")\n",
            "else:\n",
            "    print(\"Dataset not found.\\nâ†’ Run 'mimic_dataset_prep.ipynb' to generate the required dataset.\\n\")\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Create dala loaders."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from torch.utils.data import DataLoader\n",
            "from mimic_data_handler import MIMICUserDataset\n",
            "\n",
            "\n",
            "data = dataset.data\n",
            "targets = dataset.targets\n",
            "\n",
            "train_subset = MIMICUserDataset(data[train_indices], targets[train_indices])\n",
            "test_subset = MIMICUserDataset(data[test_indices], targets[test_indices])\n",
            "early_stop_subset = MIMICUserDataset(data[early_stop_indices], targets[early_stop_indices])\n",
            "\n",
            "# Create DataLoaders\n",
            "batch_size = train_config['data']['batch_size']\n",
            "train_loader = DataLoader(train_subset, batch_size=batch_size)\n",
            "test_loader = DataLoader(test_subset, batch_size=batch_size)\n",
            "early_stop_loader = DataLoader(early_stop_subset, batch_size=batch_size)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "lr  = 0,0001 for LR - weight_decay = 5.392, epochs = 20"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from target_models import LR\n",
            "from torch import  nn, optim, save\n",
            "from mimic_model_handler import LRHandler\n",
            "\n",
            "\n",
            "# Create model\n",
            "n_features = dataset.data.shape[1]\n",
            "print(f\"Number of features: {n_features}\")\n",
            "model = LR(input_dim = n_features)\n",
            "\n",
            "# Read parameters from config file\n",
            "lr = train_config['train']['LR']['learning_rate']\n",
            "weight_decay = train_config['train']['LR']['weight_decay']\n",
            "epochs = train_config['train']['LR']['epochs']\n",
            "\n",
            "# Create optimizer\n",
            "criterion = nn.BCELoss()\n",
            "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
            "\n",
            "# Train the model\n",
            "train_results = LRHandler().train(train_loader, model, criterion, optimizer, epochs)\n",
            "\n",
            "# Evaluate the model\n",
            "test_results = LRHandler().eval(test_loader, model, criterion)\n",
            "\n",
            "# Store model and its metadata\n",
            "model = train_results.model\n",
            "model.to(\"cpu\")\n",
            "target_dir = \"target_LR\"\n",
            "os.makedirs(target_dir, exist_ok=True)\n",
            "with open(target_dir+\"/target_model.pkl\", \"wb\") as f:\n",
            "    save(model.state_dict(), f)\n",
            "\n",
            "# Create metadata to be used by LeakPro\n",
            "from leakpro import LeakPro\n",
            "meta_data = LeakPro.make_mia_metadata(train_result = train_results,\n",
            "                                    optimizer = optimizer,\n",
            "                                    loss_fn = criterion,\n",
            "                                    dataloader = train_loader,\n",
            "                                    test_result = test_results,\n",
            "                                    epochs = epochs,\n",
            "                                    train_indices = train_indices,\n",
            "                                    test_indices = test_indices,\n",
            "                                    dataset_name = train_config[\"data\"][\"dataset\"])\n",
            "\n",
            "with open(target_dir + \"/model_metadata.pkl\", \"wb\") as f:\n",
            "    pickle.dump(meta_data, f)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "\n",
            "train_acc = train_results.metrics.extra[\"accuracy_history\"]\n",
            "train_loss = train_results.metrics.extra[\"loss_history\"]\n",
            "test_acc = test_results.accuracy\n",
            "test_loss = test_results.loss\n",
            "\n",
            "# Plot training and test accuracy\n",
            "plt.figure(figsize=(5, 4))\n",
            "\n",
            "plt.subplot(1, 2, 1)\n",
            "plt.plot(train_acc, label='Train Accuracy')\n",
            "plt.plot(len(train_loss)-1, test_acc, 'ro', label='Test Loss')\n",
            "plt.xlabel('Epoch')\n",
            "plt.ylabel('Accuracy')\n",
            "plt.title('Accuracy over Epochs')\n",
            "plt.legend()\n",
            "\n",
            "# Plot training and test loss\n",
            "plt.subplot(1, 2, 2)\n",
            "plt.plot(train_loss, label='Train Loss')\n",
            "plt.plot(len(train_loss)-1, test_loss, 'ro', label='Test Loss')\n",
            "plt.xlabel('Epoch')\n",
            "plt.ylabel('Loss')\n",
            "plt.title('Loss over Epochs')\n",
            "plt.legend()\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Attack the LR model\n",
            "Modify ```audit.yaml ``` file to attack LR model: \n",
            "  \n",
            "  ```\n",
            "  module_path: \"utils/model_LR.py\" \n",
            "  model_class: \"LR\"\n",
            "  target_folder: \"./target_LR\"\n",
            "  data_path: \"./data/LR_data/dataset.pkl\"\n",
            "  ```\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import sys\n",
            "from leakpro import LeakPro\n",
            "from mimic_model_handler import LRHandler as InputHandler\n",
            "\n",
            "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../../\"))  # adjust as needed\n",
            "if project_root not in sys.path:\n",
            "    sys.path.insert(0, project_root)  # insert at the front to prioritize it\n",
            "\n",
            "# Read the config file\n",
            "config_path = \"audit.yaml\"\n",
            "\n",
            "# Instantiate leakpro object\n",
            "leakpro = LeakPro(InputHandler, config_path)\n",
            "\n",
            "# Run the audit \n",
            "mia_results = leakpro.run_audit(return_results=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".leakpro_dev",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.11"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
