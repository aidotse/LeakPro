{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import zeros, tensor\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils.data_processing import get_mimic_dataset, get_mimic_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate the dataset and dataloaders\n",
    "path = os.path.join(os.getcwd(), \"data/\")\n",
    "\n",
    "train_frac = 0.475\n",
    "valid_frac = 0.2\n",
    "test_frac = 0.2\n",
    "early_stop_frac = 0.125\n",
    "batch_size = 59\n",
    "flatten = False # If LR, flatten the data\n",
    "\n",
    "dataset, train_indices, validation_indices, test_indices, early_stop_indices= get_mimic_dataset(path,\n",
    "                                                                            train_frac , \n",
    "                                                                            valid_frac,\n",
    "                                                                            test_frac,\n",
    "                                                                            early_stop_frac,\n",
    "                                                                            flatten)\n",
    "                                                                            \n",
    "                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, validation_loader, test_loader, early_stop_loader = get_mimic_dataloaders(dataset,\n",
    "                                                            train_indices, \n",
    "                                                            validation_indices, \n",
    "                                                            test_indices,\n",
    "                                                            early_stop_indices,\n",
    "                                                            batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams ={\n",
    "    'cell_size': 58,\n",
    "    'hidden_size': 78, \n",
    "    'learning_rate': 0.004738759319792616,\n",
    "    'num_epochs':37,\n",
    "    'patience': 3,\n",
    "    'batch_size': 59,\n",
    "    'early_stop_frac': 0.125,\n",
    "    'seed': 4410,\n",
    "}\n",
    "early_stop_frac = valid_frac\n",
    "n_features = int(dataset.x.shape[1]/3)\n",
    "X_mean = zeros(1,dataset.x.shape[2],n_features)\n",
    "\n",
    "model_params = {k: best_hyperparams[k] for k in ['cell_size', 'hidden_size', 'batch_size']}\n",
    "\n",
    "# Add other required parameters to model_params\n",
    "model_params.update({\n",
    "    'input_size': n_features,\n",
    "    'X_mean': X_mean,\n",
    "    'output_last': False\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23944, 312, 24])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (rl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (hl): Linear(in_features=286, out_features=78, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=78, bias=True)\n",
      "  (fc): Linear(in_features=78, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from utils.grud import *\n",
    "\n",
    "# Initialize the model with filtered parameters\n",
    "model = GRUD(**model_params)\n",
    "# Train the model with Train_Model function\n",
    "train_losses, test_losses ,  train_acc, test_acc = gru_trained_model_and_metadata(\n",
    "            model, train_loader, early_stop_loader,\n",
    "            epochs=best_hyperparams['num_epochs'], \n",
    "            patience=best_hyperparams['patience'], \n",
    "            min_delta = 1e-5,\n",
    "            learning_rate=best_hyperparams['learning_rate'], \n",
    "            batch_size=best_hyperparams['batch_size'],  # This might be used in your dataloaders, not directly in Train_Model\n",
    "             metadata = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert losses to numpy-compatible lists directly\n",
    "train_losses_cpu = [float(loss) for loss in train_losses]\n",
    "test_losses_cpu = [float(loss) for loss in test_losses]\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(train_losses_cpu, label='Train Loss')\n",
    "plt.plot(test_losses_cpu, label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimic_gru_handler import MimicInputHandlerGRU\n",
    "\n",
    "from leakpro import LeakPro\n",
    "\n",
    "# Read the config file\n",
    "config_path = \"audit.yaml\"\n",
    "\n",
    "# Prepare leakpro object\n",
    "leakpro = LeakPro(MimicInputHandlerGRU, config_path)\n",
    "\n",
    "# Run the audit \n",
    "leakpro.run_audit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leakpro_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
