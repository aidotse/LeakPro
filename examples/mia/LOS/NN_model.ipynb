{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import zeros, tensor\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils.data_processing import get_mimic_dataset, get_mimic_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m59\u001b[39m\n\u001b[1;32m      9\u001b[0m flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# If LR, flatten the data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m dataset, train_indices, validation_indices, test_indices, early_stop_indices\u001b[38;5;241m=\u001b[39m get_mimic_dataset(path,\n\u001b[1;32m     12\u001b[0m                                                                             train_frac , \n\u001b[1;32m     13\u001b[0m                                                                             valid_frac,\n\u001b[1;32m     14\u001b[0m                                                                             test_frac,\n\u001b[1;32m     15\u001b[0m                                                                             early_stop_frac,\n\u001b[1;32m     16\u001b[0m                                                                             flatten)\n",
      "File \u001b[0;32m~/LeakPro/examples/mia/LOS/utils/data_processing.py:84\u001b[0m, in \u001b[0;36mget_mimic_dataset\u001b[0;34m(data_path, train_frac, validation_frac, test_frac, early_stop_frac, flatten)\u001b[0m\n\u001b[1;32m     82\u001b[0m data_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_hourly_data.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(data_file_path):\n\u001b[0;32m---> 84\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_hdf(data_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvitals_labs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m     statics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_hdf(data_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatients\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     87\u001b[0m     ID_COLS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhadm_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124micustay_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/io/pytables.py:452\u001b[0m, in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey must be provided when HDF5 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile contains multiple datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m         key \u001b[38;5;241m=\u001b[39m candidate_only_group\u001b[38;5;241m.\u001b[39m_v_pathname\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m store\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m    453\u001b[0m         key,\n\u001b[1;32m    454\u001b[0m         where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[1;32m    455\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart,\n\u001b[1;32m    456\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    457\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m    458\u001b[0m         iterator\u001b[38;5;241m=\u001b[39miterator,\n\u001b[1;32m    459\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    460\u001b[0m         auto_close\u001b[38;5;241m=\u001b[39mauto_close,\n\u001b[1;32m    461\u001b[0m     )\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mLookupError\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, HDFStore):\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# if there is an error, close the store if we opened it.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/io/pytables.py:906\u001b[0m, in \u001b[0;36mHDFStore.select\u001b[0;34m(self, key, where, start, stop, columns, iterator, chunksize, auto_close)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# create the iterator\u001b[39;00m\n\u001b[1;32m    893\u001b[0m it \u001b[38;5;241m=\u001b[39m TableIterator(\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    895\u001b[0m     s,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m     auto_close\u001b[38;5;241m=\u001b[39mauto_close,\n\u001b[1;32m    904\u001b[0m )\n\u001b[0;32m--> 906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m it\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/io/pytables.py:2029\u001b[0m, in \u001b[0;36mTableIterator.get_result\u001b[0;34m(self, coordinates)\u001b[0m\n\u001b[1;32m   2026\u001b[0m     where \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere\n\u001b[1;32m   2028\u001b[0m \u001b[38;5;66;03m# directly return the result\u001b[39;00m\n\u001b[0;32m-> 2029\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop, where)\n\u001b[1;32m   2030\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/io/pytables.py:890\u001b[0m, in \u001b[0;36mHDFStore.select.<locals>.func\u001b[0;34m(_start, _stop, _where)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(_start, _stop, _where):\n\u001b[0;32m--> 890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mread(start\u001b[38;5;241m=\u001b[39m_start, stop\u001b[38;5;241m=\u001b[39m_stop, where\u001b[38;5;241m=\u001b[39m_where, columns\u001b[38;5;241m=\u001b[39mcolumns)\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/io/pytables.py:3301\u001b[0m, in \u001b[0;36mBlockManagerFixed.read\u001b[0;34m(self, where, columns, start, stop)\u001b[0m\n\u001b[1;32m   3298\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m   3300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dfs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3301\u001b[0m     out \u001b[38;5;241m=\u001b[39m concat(dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m   3303\u001b[0m         \u001b[38;5;66;03m# with CoW, concat ignores the copy keyword. Here, we still want\u001b[39;00m\n\u001b[1;32m   3304\u001b[0m         \u001b[38;5;66;03m# to copy to enforce optimized column-major layout\u001b[39;00m\n\u001b[1;32m   3305\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/core/internals/concat.py:131\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Assertions disabled for performance\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m#    indexers = tup[1]\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concat_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 131\u001b[0m     mgrs \u001b[38;5;241m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers, needs_copy)\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mgrs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mconcat_horizontal(mgrs, axes)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mgrs_indexers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mgrs_indexers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnblocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/core/internals/concat.py:230\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[0;34m(axes, mgrs_indexers, needs_copy)\u001b[0m\n\u001b[1;32m    220\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    221\u001b[0m             axes[i],\n\u001b[1;32m    222\u001b[0m             indexers[i],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m             use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# only relevant for i==0\u001b[39;00m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m needs_copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexers:\n\u001b[0;32m--> 230\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m mgr\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    232\u001b[0m     new_mgrs\u001b[38;5;241m.\u001b[39mappend(mgr)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgrs\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/core/internals/managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m, deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[1;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/miniconda3/envs/leakpro_test/lib/python3.12/site-packages/pandas/core/internals/blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate the dataset and dataloaders\n",
    "path = os.path.join(os.getcwd(), \"data/\")\n",
    "\n",
    "train_frac = 0.475\n",
    "valid_frac = 0.2\n",
    "test_frac = 0.2\n",
    "early_stop_frac = 0.125\n",
    "batch_size = 59\n",
    "flatten = False # If LR, flatten the data\n",
    "\n",
    "dataset, train_indices, validation_indices, test_indices, early_stop_indices= get_mimic_dataset(path,\n",
    "                                                                            train_frac , \n",
    "                                                                            valid_frac,\n",
    "                                                                            test_frac,\n",
    "                                                                            early_stop_frac,\n",
    "                                                                            flatten)\n",
    "                                                                            \n",
    "                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, validation_loader, test_loader, early_stop_loader = get_mimic_dataloaders(dataset,\n",
    "                                                            train_indices, \n",
    "                                                            validation_indices, \n",
    "                                                            test_indices,\n",
    "                                                            early_stop_indices,\n",
    "                                                            batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams ={\n",
    "    'cell_size': 58,\n",
    "    'hidden_size': 78, \n",
    "    'learning_rate': 0.004738759319792616,\n",
    "    'num_epochs':37,\n",
    "    'patience': 3,\n",
    "    'batch_size': 59,\n",
    "    'early_stop_frac': 0.125,\n",
    "    'seed': 4410,\n",
    "}\n",
    "early_stop_frac = valid_frac\n",
    "n_features = int(dataset.x.shape[1]/3)\n",
    "X_mean = zeros(1,dataset.x.shape[2],n_features)\n",
    "\n",
    "model_params = {k: best_hyperparams[k] for k in ['cell_size', 'hidden_size', 'batch_size']}\n",
    "\n",
    "# Add other required parameters to model_params\n",
    "model_params.update({\n",
    "    'input_size': n_features,\n",
    "    'X_mean': X_mean,\n",
    "    'output_last': False\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from utils.grud import *\n",
    "\n",
    "# Initialize the model with filtered parameters\n",
    "model = GRUD(**model_params)\n",
    "# Train the model with Train_Model function\n",
    "train_losses, test_losses ,  train_acc, test_acc = gru_trained_model_and_metadata(\n",
    "            model, train_loader, early_stop_loader,\n",
    "            epochs=best_hyperparams['num_epochs'], \n",
    "            patience=best_hyperparams['patience'], \n",
    "            min_delta = 1e-5,\n",
    "            learning_rate=best_hyperparams['learning_rate'], \n",
    "            batch_size=best_hyperparams['batch_size'],  # This might be used in your dataloaders, not directly in Train_Model\n",
    "             metadata = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert losses to numpy-compatible lists directly\n",
    "train_losses_cpu = [float(loss) for loss in train_losses]\n",
    "test_losses_cpu = [float(loss) for loss in test_losses]\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(train_losses_cpu, label='Train Loss')\n",
    "plt.plot(test_losses_cpu, label='Test Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mimic_gru_handler import MimicInputHandlerGRU\n",
    "\n",
    "from leakpro import LeakPro\n",
    "\n",
    "# Read the config file\n",
    "config_path = \"audit.yaml\"\n",
    "\n",
    "# Prepare leakpro object\n",
    "leakpro = LeakPro(MimicInputHandlerGRU, config_path)\n",
    "\n",
    "# Run the audit \n",
    "leakpro.run_audit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leakpro_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
