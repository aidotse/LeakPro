{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR vectorized LiRA example\n",
    "\n",
    "This notebook mirrors A_cifar_main.ipynb but configures the LiRA attack to use the vectorized fast path.\n",
    "\n",
    "It is safer to delete previous results for target and shadow models as it will train new models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "train_config_path = \"train_robust.yaml\"\n",
    "audit_config_path = \"audit_robust.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the population dataset by concatenating the train and test data. To create the population, we make use of the UserDataset provided in the InputHandler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from torch import cat, tensor\n",
    "import pickle\n",
    "from cifar_handler import CifarInputHandler\n",
    "\n",
    "# Load the config.yaml file\n",
    "with open(train_config_path, 'r') as file:\n",
    "    train_config = yaml.safe_load(file)\n",
    "\n",
    "data_root = train_config[\"data\"][\"data_dir\"]\n",
    "data_path = os.path.join(os.getcwd(), data_root)\n",
    "\n",
    "# Load the CIFAR train and test datasets\n",
    "if train_config[\"data\"][\"dataset\"] == \"cifar10\":\n",
    "    trainset = CIFAR10(root=data_root, train=True, download=True)\n",
    "    testset = CIFAR10(root=data_root, train=False, download=True)\n",
    "elif train_config[\"data\"][\"dataset\"] == \"cifar100\":\n",
    "    trainset = CIFAR100(root=data_root, train=True, download=True)\n",
    "    testset = CIFAR100(root=data_root, train=False, download=True)\n",
    "else:\n",
    "    raise ValueError(\"Unknown dataset type\")\n",
    "\n",
    "train_data = tensor(trainset.data).permute(0, 3, 1, 2).float() / 255  # (N, C, H, W)\n",
    "test_data = tensor(testset.data).permute(0, 3, 1, 2).float() / 255\n",
    "\n",
    "# Ensure train and test data looks correct\n",
    "assert train_data.shape[0] == 50000, \"Train data should have 50000 samples\"\n",
    "assert test_data.shape[0] == 10000, \"Test data should have 10000 samples\"\n",
    "assert train_data.shape[1] == 3, \"Data should have 3 channels\"\n",
    "assert test_data.shape[1] == 3, \"Data should have 3 channels\"\n",
    "assert train_data.max() <= 1 and train_data.min() >= 0, \"Data should be normalized\"\n",
    "assert test_data.max() <= 1 and test_data.min() >= 0, \"Data should be normalized\"\n",
    "\n",
    "# Concatenate train and test data into the population\n",
    "data = cat([train_data.clone().detach(), test_data.clone().detach()], dim=0)\n",
    "targets = cat([tensor(trainset.targets), tensor(testset.targets)], dim=0)\n",
    "# Create UserDataset object\n",
    "population_dataset = CifarInputHandler.UserDataset(data, targets)\n",
    "\n",
    "assert len(population_dataset) == 60000, \"Population dataset should have 60000 samples\"\n",
    "\n",
    "# Store the population dataset to be used by LeakPro \n",
    "dataset_name = train_config[\"data\"][\"dataset\"]\n",
    "file_path =  data_root+\"/\"+ dataset_name + \".pkl\"\n",
    "if not os.path.exists(file_path):\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        pickle.dump(population_dataset, file)\n",
    "        print(f\"Save data to {file_path}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "With the population dataset stored, we next create the train and test set that will go in to training the target model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train size: 50000, test size: 10000\n",
      "selected train size: 30000, test size: 30000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "train_fraction = train_config[\"data\"][\"f_train\"]\n",
    "test_fraction = train_config[\"data\"][\"f_test\"]\n",
    "batch_size = train_config[\"train\"][\"batch_size\"]\n",
    "\n",
    "dataset_size = len(population_dataset)\n",
    "train_size = int(train_fraction * dataset_size) \n",
    "test_size = int(test_fraction * dataset_size)\n",
    "print(f\"original train size: {len(train_data)}, test size: {len(test_data)}\")\n",
    "print(f\"selected train size: {train_size}, test size: {test_size}\")\n",
    "\n",
    "randomize_audit = False\n",
    "selected_index = np.arange(train_size + test_size)\n",
    "if randomize_audit:\n",
    "    np.random.shuffle(selected_index)\n",
    "train_indices = selected_index[:train_size]\n",
    "test_indices = selected_index[train_size:(train_size+test_size)]\n",
    "\n",
    "# Now define the new target train and test sets\n",
    "train_subset = CifarInputHandler.UserDataset(data[train_indices], targets[train_indices])\n",
    "test_subset = CifarInputHandler.UserDataset(data[test_indices], targets[test_indices], **train_subset.return_params())\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_subset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# Evaluate mean and variance of the train data\n",
    "#train_mean = train_subset.mean\n",
    "#train_std = train_subset.std\n",
    "#print (f\"Train mean: {train_mean}\")\n",
    "#print (f\"Train std: {train_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train target model\n",
    "With the train and test dataloader in place, we train a ResNet18. \n",
    "After training, we call LeakPro to create metadata that will be used during auditing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_dir: ./robust/target\n"
     ]
    }
   ],
   "source": [
    "target_dir = train_config[\"run\"][\"log_dir\"]\n",
    "print(\"target_dir:\", target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: 100%|██████████| 106/106 [00:08<00:00, 11.81it/s, acc=0.3943, loss=1.7106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 1: 1.5474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 106/106 [00:08<00:00, 12.53it/s, acc=0.5584, loss=1.2296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 2: 1.1909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 106/106 [00:08<00:00, 12.73it/s, acc=0.6414, loss=1.0012]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 3: 1.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 106/106 [00:08<00:00, 12.80it/s, acc=0.7109, loss=0.8185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 4: 1.0699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 106/106 [00:08<00:00, 12.85it/s, acc=0.7631, loss=0.6712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 5: 1.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 106/106 [00:08<00:00, 12.83it/s, acc=0.8044, loss=0.5604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 6: 0.8484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 106/106 [00:08<00:00, 12.82it/s, acc=0.8370, loss=0.4625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 7: 0.7824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 106/106 [00:08<00:00, 12.67it/s, acc=0.8655, loss=0.3812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 8: 0.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 106/106 [00:08<00:00, 12.71it/s, acc=0.8990, loss=0.2954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 9: 0.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 106/106 [00:08<00:00, 12.73it/s, acc=0.9215, loss=0.2278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 10: 0.8161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 106/106 [00:08<00:00, 12.83it/s, acc=0.9441, loss=0.1630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 11: 0.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 106/106 [00:08<00:00, 12.63it/s, acc=0.9560, loss=0.1281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch 12: 0.8383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25:  96%|█████████▌| 102/106 [00:08<00:00, 12.58it/s, acc=0.9780, loss=0.0721]"
     ]
    }
   ],
   "source": [
    "from torch import save, optim, nn\n",
    "from target_model_class import ResNet18, WideResNet\n",
    "\n",
    "# Train the model\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "    \n",
    "if train_config[\"data\"][\"dataset\"] == \"cifar10\":\n",
    "    num_classes = 10\n",
    "elif train_config[\"data\"][\"dataset\"] == \"cifar100\":\n",
    "    num_classes = 100\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset name\")\n",
    "\n",
    "# Create instance of target model\n",
    "#model = ResNet18(num_classes = num_classes)\n",
    "model =  WideResNet(depth=28, num_classes=num_classes, widen_factor=2)\n",
    "\n",
    "# Read out the relevant parameters for training\n",
    "lr = train_config[\"train\"][\"learning_rate\"]\n",
    "weight_decay = train_config[\"train\"][\"weight_decay\"]\n",
    "momentum = train_config[\"train\"][\"momentum\"]\n",
    "epochs = train_config[\"train\"][\"epochs\"]\n",
    "    \n",
    "# Create optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# train target model\n",
    "train_result = CifarInputHandler().train(dataloader=train_loader,\n",
    "                            model=model,\n",
    "                            criterion=criterion,\n",
    "                            optimizer=optimizer,\n",
    "                            epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_result = CifarInputHandler().eval(test_loader, model, criterion)\n",
    "\n",
    "# Store the model and metadata\n",
    "model = train_result.model\n",
    "model.to(\"cpu\")\n",
    "#with open(train_config[\"run\"][\"log_dir\"]+\"/target_model.pkl\", \"wb\") as f:\n",
    "with open(target_dir+\"/target_model.pkl\", \"wb\") as f:\n",
    "    save(model.state_dict(), f)\n",
    "\n",
    "# Create metadata to be used by LeakPro\n",
    "from leakpro import LeakPro\n",
    "meta_data = LeakPro.make_mia_metadata(train_result = train_result,\n",
    "                                      optimizer = optimizer,\n",
    "                                      loss_fn = criterion,\n",
    "                                      dataloader = train_loader,\n",
    "                                      test_result = test_result,\n",
    "                                      epochs = epochs,\n",
    "                                      train_indices = train_indices,\n",
    "                                      test_indices = test_indices,\n",
    "                                      dataset_name = dataset_name)\n",
    "\n",
    "with open(target_dir+\"/model_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(meta_data, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot accuracy and test of training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc = train_result.metrics.extra[\"accuracy_history\"]\n",
    "train_loss = train_result.metrics.extra[\"loss_history\"]\n",
    "test_acc = test_result.accuracy\n",
    "test_loss = test_result.loss\n",
    "\n",
    "# Plot training and test accuracy\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(len(train_loss)-1, test_acc, 'ro', label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and test loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(len(train_loss)-1, test_loss, 'ro', label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train shadow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from leakpro.schemas import LeakProConfig\n",
    "\n",
    "with open(audit_config_path, \"rb\") as f:\n",
    "    audit_configs = yaml.safe_load(f)\n",
    "leakpro_configs = LeakProConfig(**audit_configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_dir = audit_configs[\"audit\"][\"output_dir\"]\n",
    "print(\"shadow_dir:\", shadow_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from leakpro.attacks.mia_attacks.lira import AttackLiRA\n",
    "from leakpro.attacks.utils.shadow_model_handler import ShadowModelHandler\n",
    "#from shadow_model_handler import ShadowModelHandler # less verbose\n",
    "from leakpro.input_handler.mia_handler import MIAHandler\n",
    "\n",
    "from cifar_handler import CifarInputHandler\n",
    "\n",
    "# Create the handler, it mostly serves as a dummy handler needed to init the attack but it also creates a dataloader,\n",
    "# contains the metadata for creating the attack and how shadow models are created for example.\n",
    "\n",
    "handler = MIAHandler(leakpro_configs, CifarInputHandler)\n",
    "\n",
    "#configs = handler.configs.audit.attack_list[0] \n",
    "for configs in handler.configs.audit.attack_list:\n",
    "    if configs[\"attack\"] == \"lira\" and configs[\"online\"]== True:        \n",
    "        print(f'found online lira attack')\n",
    "        attack = AttackLiRA(handler=handler, configs=configs)\n",
    "        break\n",
    "    else:\n",
    "        print(f'attack {configs[\"attack\"]} is not lira')\n",
    "        attack = None\n",
    "\n",
    "assert configs[\"attack\"]=='lira', \"ERROR: attack must be lira\"\n",
    "assert configs[\"online\"]== True, \"ERROR: attack must online\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get attack data indices. If true, the whole population is used, otherwise exclude the training data.\n",
    "attack_data_indices = attack.sample_indices_from_population(include_train_indices = True, include_test_indices = True)\n",
    "\n",
    "training_data_fraction = attack.training_data_fraction # Use the same fraction as the target model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of shadow models to train\n",
    "num_shadow_models = configs[\"num_shadow_models\"]\n",
    "\n",
    "# Train shadow models\n",
    "#print(\"Note that incremental is set to \", INCREMENTAL)\n",
    "#print(\"Note that shuffle_shift is set to \", SHUFFLE_SHIFT)\n",
    "shadow_model_indices = ShadowModelHandler(handler).create_shadow_models(num_models = num_shadow_models,\n",
    "                                                                shadow_population =  attack_data_indices,\n",
    "                                                                training_fraction = training_data_fraction,\n",
    "                                                                online = True, \n",
    "                                                                #verbose = False,\n",
    "                                                                #incremental = INCREMENTAL, \n",
    "                                                                #shuffle_shift = SHUFFLE_SHIFT\n",
    "                                                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the signal function from the attack like this\n",
    "#signal = attack.signal\n",
    "\n",
    "# Set the batch size we want to use for the signal function to extract signals faster\n",
    "attack.handler.dataloader_config.params[\"batch_size\"] = 1024\n",
    "\n",
    "# Extract our logits\n",
    "#target_models_logits = np.swapaxes(signal([attack.target_model],\n",
    "#                                    attack.handler,\n",
    "#                                    audit_dataset[\"data\"],\n",
    "#                                ), 0, 1).squeeze()\n",
    "\n",
    "#print(\"target_models_logits\", target_models_logits.shape)\n",
    "\n",
    "attack.prepare_attack()\n",
    "\n",
    "print(attack.shadow_models_logits.shape, attack.target_logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the audit dataset from the attack\n",
    "audit_dataset = attack.audit_dataset\n",
    "audit_data_indices = audit_dataset[\"data\"]\n",
    "\n",
    "# Reconstruct the audit data indices array\n",
    "target_audit_data_indices = np.concatenate([train_indices, test_indices])\n",
    "assert all(audit_data_indices == target_audit_data_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create in indices mask for target model compliant with those for shadow\n",
    "target_in_indices_mask = np.zeros_like(target_audit_data_indices)\n",
    "target_in_indices_mask[:len(train_indices)] = 1\n",
    "target_in_indices_mask = target_in_indices_mask.astype(bool)\n",
    "target_in_indices_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get in indices mask for shadow models \n",
    "\n",
    "in_indices_masks = ShadowModelHandler(handler).get_in_indices_mask(shadow_model_indices, audit_dataset[\"data\"])#.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = target_dir + \"/signals\"\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "\n",
    "print(\"store target results in \", filepath)\n",
    "\n",
    "np.save(filepath + \"/rescaled_logits.npy\", attack.target_logits[:,None]) # make it 2D array\n",
    "np.save(filepath + \"/in_indices_masks.npy\", target_in_indices_mask[:,None]) #  make it 2D array\n",
    "np.save(filepath + \"/audit_data_indices.npy\", target_audit_data_indices)\n",
    "\n",
    "print(\"attack.target_logits\", attack.target_logits.shape)\n",
    "print(\"target_in_indices_mask\", target_in_indices_mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = shadow_dir + \"/signals\"\n",
    "os.makedirs(filepath, exist_ok=True)\n",
    "\n",
    "print(\"store shadow results in \", filepath)\n",
    "\n",
    "np.save(filepath + \"/rescaled_logits.npy\", attack.shadow_models_logits.T)\n",
    "np.save(filepath + \"/in_indices_masks.npy\", in_indices_masks)\n",
    "np.save(filepath + \"/audit_data_indices.npy\", audit_data_indices)\n",
    "\n",
    "print(\"shadow_models_logits\", attack.shadow_models_logits.shape)\n",
    "print(\"in_indices_masks\", in_indices_masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
