audit:  # Configurations for auditing
  random_seed: 1234  # Integer specifying the random seed
  attack_list:
    rmia:
      training_data_fraction: 0.5  # Fraction of the auxilary dataset to use for this attack (in each shadow model training)
      attack_data_fraction: 0.5 # Fraction of auxiliary dataset to sample from during attack
      num_shadow_models: 3 # Number of shadow models to train
      online: True # perform online or offline attack
    qmia:
      training_data_fraction: 1.0  # Fraction of the auxilary dataset (data without train and test indices) to use for training the quantile regressor
      epochs: 5  # Number of training epochs for quantile regression
    population:
      attack_data_fraction: 1.0  # Fraction of the auxilary dataset to use for this attack
    lira:
      training_data_fraction: 0.5  # Fraction of the auxilary dataset to use for this attack (in each shadow model training)
      num_shadow_models: 8 # Number of shadow models to train
      online: False # perform online or offline attack
      fixed_variance: True # Use a fixed variance for the whole audit
      boosting: True
    loss_traj:
      training_distill_data_fraction : 0.7 # Fraction of the auxilary dataset to use for training the distillation models D_s = (1-D_KD)/2
      number_of_traj: 10 # Number of epochs (number of points in the loss trajectory)
      label_only: False # True or False
      mia_classifier_epochs: 100
    yoqo:
      training_data_fraction: 0.5  # Fraction of the auxilary dataset to use for this attack (in each shadow model training)
      num_shadow_models: 8 # Number of shadow models to train
      online: True # perform online or offline attack
      lr_xprime_optimization: .01
      max_iterations: 35

  output_dir: "./leakpro_output"
  attack_type: "mia" #mia, gia
  data_modality: "tabular"

target:
  # Target model path
  module_path: "utils/adult_model_preparation.py"
  model_class: "AdultNet" 
  # Data paths
  target_folder: "./target"
  data_path: "./data/adult_data.pkl"

shadow_model:
  
distillation_model:
