"""Parent class for user inputs."""

import logging
from abc import ABC, abstractmethod

import joblib
import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader

from leakpro.import_helper import Self, Tuple
from leakpro.utils.input_handler import get_class_from_module, import_module_from_file


class AbstractInputHandler(ABC):
    """Parent class for user inputs."""

    def __init__(self:Self, configs: dict, logger:logging.Logger) -> None:
        self.configs = configs
        self.logger = logger

        # These objects will be generated by the setup function and then saved in the handler object
        self.target_model_blueprint = None
        self.target_model = None
        self.target_model_metadata = None
        self.population = None

        self.setup()

        # User-defined attributes
        self.criterion = None
        self.optimizer = None

    # must be called after initialization
    def setup(self:Self) -> None:
        """Set up the code handler by retrieving the model class, target metadata, trained target model, and population."""
        self._load_model_class()
        self._load_target_metadata()
        self._load_trained_target_model()
        self._load_population()

    def _load_population(self:Self) -> None:
        """Default implementation of the population loading."""
        try:
            with open(self.configs["target"]["data_path"], "rb") as file:
                self.population = joblib.load(file)
                self.logger.info(f"Loaded population dataset from {self.configs['target']['data_path']}")
            self.logger.info(f"Loaded population dataset from {self.configs['target']['data_path']}")
        except FileNotFoundError as e:
            raise FileNotFoundError(f"Could not find the population dataset at {self.configs['target']['data_path']}") from e

    def _load_model_class(self:Self) -> None:
        """Get the model class blueprint from the target module."""
        model_class=self.configs["target"].get("model_class", None)
        if model_class is None:
            raise ValueError("model_class not found in configs.")

        module_path=self.configs["target"].get("module_path", None)
        if module_path is None:
            raise ValueError("module_path not found in configs.")

        try:
            target_module = import_module_from_file(module_path)
            self._target_model_blueprint = get_class_from_module(target_module, model_class)
            self.logger.info(f"Target model blueprint created from {model_class} in {module_path}.")
        except Exception as e:
            raise ValueError(f"Failed to create the target model blueprint from {model_class} in {module_path}") from e

    def _validate_target_metadata(self:Self) -> None:
        """Validate the target model metadata."""
        if "train_indices" not in self.target_model_metadata:
            raise ValueError("train_indices not found in target model metadata.")

        if "test_indices" not in self.target_model_metadata:
            raise ValueError("test_indices not found in target model metadata.")

    def _load_target_metadata(self:Self) -> None:
        """Get the target model metadata from the trained model metadata file."""
        target_model_metadata_path = self.configs["target"].get("trained_model_metadata_path", None)
        if target_model_metadata_path is None:
            raise ValueError("Trained model metadata path not found in configs.")
        try:
            with open(target_model_metadata_path, "rb") as f:
                self.target_model_metadata = joblib.load(f)
                self._validate_target_metadata()
            self.logger.info(f"Loaded target model metadata from {target_model_metadata_path}")
        except FileNotFoundError as e:
            raise FileNotFoundError(f"Could not find the target model metadata at {target_model_metadata_path}") from e

    def _load_trained_target_model(self:Self) -> None:
        """Get the trained target model."""
        model_path = self.configs["target"].get("trained_model_path", None)
        if model_path is None:
            raise ValueError("Trained model path not found in configs.")
        init_params = self.target_model_metadata.get("init_params", {})
        try:
            with open(self.configs["target"]["trained_model_path"], "rb") as f:
                self.target_model = self.target_model_blueprint(**init_params)
                self.target_model.load_state_dict(torch.load(f))
            self.logger.info(f"Loaded target model from {model_path}")
        except FileNotFoundError as e:
            raise FileNotFoundError(f"Could not find the trained target model at {model_path}") from e

    #------------------------------------------------
    # Methods related to population dataset
    #------------------------------------------------
    def _validate_indices(self:Self, dataset_indices: np.ndarray) -> None:
        if self.population is None:
            raise ValueError("Population dataset is not loaded.")

        if len(dataset_indices) == 0:
            raise ValueError("Dataset indices are empty.")

        if len(dataset_indices) > len(self.population):
            raise ValueError("Dataset indices are greater than the population size.")

        if len(dataset_indices) != len(np.unique(dataset_indices)):
            raise ValueError("Dataset indices contain duplicates.")

        if not np.all(dataset_indices < len(self.population)):
            raise ValueError("Dataset indices contain values greater than the population size.")

        if not np.all(dataset_indices >= 0):
            raise ValueError("Dataset indices contain negative values.")

        if not np.all(np.isfinite(dataset_indices)):
            raise ValueError("Dataset indices contain non-finite values.")

        if not np.issubdtype(dataset_indices.dtype, np.integer):
            raise ValueError("Dataset indices are not integers.")

    def get_dataset(self:Self, dataset_indices: np.ndarray) -> np.ndarray:
        """Get the dataset from the population."""
        self._validate_indices(dataset_indices)
        return self.population.subset(dataset_indices)

    def get_dataloader(self: Self, dataset_indices: np.ndarray, batch_size: int = 32) -> DataLoader:
        """Default implementation of the dataloader."""
        dataset = self.get_dataset(dataset_indices)
        return DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)

    #------------------------------------------------
    # Methods related to target model
    #------------------------------------------------
    def get_target_replica(self:Self) -> Tuple[torch.nn.Module, nn.modules.loss._Loss, torch.optim.Optimizer]:
        """Get an instance of a model created from the target model."""
        init_params = self.target_model_metadata["model_metadata"].get("init_params", {})
        try:
            model_replica = self.target_model_blueprint(**init_params)
            return model_replica, self.criterion, self.set_optimizer(model_replica)
        except Exception as e:
            raise ValueError("Failed to create an instance of the shadow model.") from e

    @abstractmethod
    def set_criterion(self:Self, criterion: torch.nn.modules.loss._Loss) -> None:
        """Define the loss function for the target model to be used in shadow model training."""
        pass

    @abstractmethod
    def set_optimizer(self:Self, model:torch.nn.Module) -> torch.optim.Optimizer:
        """Define the optimizer used for the target model to be used in shadow model training."""
        pass

    @abstractmethod
    def train(
        self: Self,
        dataloader: DataLoader,
        model: torch.nn.Module,
        criterion: torch.nn.modules.loss._Loss,
        optimizer: torch.optim.Optimizer
    ) -> nn.Module:
        """Procedure to train the shadow models on data from the population."""
        pass

    #------------------------------------------------
    # get-set methods
    #------------------------------------------------
    @property
    def target_model_blueprint(self:Self) -> torch.nn.Module:
        """Get the target model blueprint."""
        return self._target_model_blueprint

    @target_model_blueprint.setter
    def target_model_blueprint(self:Self, value:torch.nn.Module) -> None:
        """Set the target model blueprint."""
        self._target_model_blueprint = value

    @property
    def target_model(self:Self) -> torch.nn.Module:
        """Get the trained target model wrapped as PyTorchModel."""
        return self._target_model

    @target_model.setter
    def target_model(self:Self, value:torch.nn.Module) -> None:
        """Set the trained target model."""
        self._target_model = value

    @property
    def target_model_metadata(self:Self) -> dict:
        """Get the metadata of the target model."""
        return self._target_model_metadata

    @target_model_metadata.setter
    def target_model_metadata(self:Self, value:dict) -> None:
        """Set the metadata of the target model."""
        self._target_model_metadata = value

    @property
    def population_size(self:Self) -> int:
        """Get the size of the population."""
        return len(self.population)

    @property
    def train_indices(self:Self) -> np.ndarray:
        """Get the training indices of the target model."""
        return self.target_model_metadata["train_indices"]

    @property
    def test_indices(self:Self) -> np.ndarray:
        """Get the testing indices of the target model."""
        return self.target_model_metadata["test_indices"]
